## 01. 从输入 URL 到页面呈现都发生了什么？

1. URL 解析

问题：
  - http 与 https 的区别
  - 有哪些传输协议：HTTP(超文本传输协议)，HTTPS(HTTP+SSL)，FTP
  - http 默认端口 80，https 默认端口 443，ftp 默认端口 21
  - 编码：encodeURI(url) / encodeURIComponent(参数) / escape(并不是所有的后端语言都支持)
  - URI(统一资源标识符) URL(统一资源定位符) URN(统一资源名称)，URL和URN都是URI的子集

http 与 https 的区别：
  1. http协议传输的数据是未加密的，也就是说是明文的，不安全。https 是 http + ssl，ssl 协议对 http 协议传输的数据进行加密，也就是说 https 可进行加密传输，身份认证，更安全
  2. http 的默认端口是 80，https 的默认端口是 443
  3. http 的连接时无状态的，https 是由 ssl 和 http 协议构建的可进行加密传输和身份认证的协议
  4. https 需要申请到 ca 申请证书，需要一定的费用

https 工作的原理(加密数据)：
  1. 客户端使用 https 的 url 访问服务器，需要与服务器建立 ssl 连接
  2. 服务器收到请求后，会将网站的证书信息(包含公钥)传输给客户端。
  3. 客户端与服务器协商 ssl 连接的安全等级，双方同意安全等级，建立会话密钥(使用对称加密生成会话密钥)
  4. 客户端利用服务器传过来的公钥将会话密钥加密(非对称加密)，并传送给服务器
  5. 服务器利用自己的私钥解密出会话密钥
  6. 服务器利用会话密钥加密数据与客户端之间的通信

https 数据加密后可以避免被劫持，但是如何保证数据没有被篡改呢
  1. 服务器利用 hash 函数，对要传递给客户端的数据生成一个摘要信息，并对摘要信息用私钥加密后一起发送给客户端
  2. 客户端利用公钥对信息解密，得到摘要信息
  3. 利用 hash 函数对原数据处理，生成摘要信息
  4. 比对，如果两个摘要信息一致，则数据未被篡改

上述理论的基础都是建立在公钥是正确的基础上，那 https 如何验证公钥没有被篡改呢？
  1. 首先浏览器读取证书中的证书所有者、有效期等信息进行一一验证
  2. 浏览器开始查找操作系统中已内置的受信任的证书发布机构CA，与浏览器发来的证书的颁发者CA比对，用于校验证书是否为合法机构颁发
  3. 如果找不到，浏览器会报错，说明服务器发来的证书是不可信任的；如果找到，浏览器就会从操作系统中取出颁发者CA的公钥，然后对服务器发来的证书里面的签名进行解密
  4. 浏览器使用相同的 hash 算法根据证书内容计算出摘要信息，将这个计算的值与证书解密的值进行比对
  5. 对比结果一致，则说明服务器发来的证书合法

数字证书包含哪些内容？
  1. 证书的发布机构CA
  2. 证书的有效期
  3. 公钥
  4. 证书所有者
  5. 签名

https 的缺点：
  1. https 协议握手阶段耗时较长，会使页面加载的时间延长50%左右
  2. https 缓存不如 http 高效，会增加数据开销
  3. ssl 证书需要费用
  4. ssl 证书需要绑定 IP。不能在同一个 IP 上绑定多个域名

2. 缓存检查 -- 产品性能优化的重点

先检测是否有强缓存
  + 有，走强缓存
  + 没有或缓存失效
检测是否有协商缓存
  + 有，走协商缓存
  - 没有，获取最新的数据

缓存位置：
  - Memory Cache: 内存缓存(内存条)
  - Disk Cache: 硬盘缓存(磁盘)

1. 内存缓存：内存缓存具有两个特点，分别是快速读取和时效性
  快速读取：内存缓存会将编译解析后的文件，直接放入该进程的内存中，占据改进程一定的内存资源，以便下次云讯使用时的快速读取
  时效性：一旦该进程关闭，则该进程的内存就会清空

2. 硬盘缓存：硬盘缓存则是直接将缓存写入硬盘文件中，读取缓存需要对缓存存放的磁盘文件进行 I/O 操作，然后重新解析该缓存内容，读取复杂，速度比内存缓存慢。退出进程不出清空。

一般 JS 字体 图片等会放在内存中，而 CSS 则会放在硬盘缓存中

浏览器读取缓存的顺序 memory > disk

打开网页：查找 Disk Cache 中是否有匹配，如有则使用，如没有则发送网络请求
刷新页面(F5)：因 TAB 没关闭，因此 Memory Cache 是可用的，会被优先使用，其次才是 Disk Cache
强制刷新(Ctrl + F5)：浏览器不适用缓存，因此发送的请求均带有 Cache-control: no-cache，服务器直接返回200和最新内容

`强缓存 Expires(HTTP/1.0) / Cache-control(HTTP/1.1)`

  浏览器对于强缓存的处理：根据第一次请求资源时返回的响应头来确定的
  
  - Expires: 缓存过期时间，用来指定资源到期的时间(HTTP/1.0)
  - Cache-Control: cache-control: max-age=2592000 第一次拿到资源后的2592000秒内(30天)，再次发送请求，读取缓存中的信息(HTTP/1.1)
  - 两者都存在的话，Cache-Control 优先级高于 Expires

强缓存是由服务端设置的，并且基于响应头返回给客户端，客户端浏览器接收到响应后，会自己建立缓存机制，不需前端人员写代码处理

Expires 的值是一个绝对时间的 GMT 格式的时间字符串，由于失效时间是一个绝对时间，所以当服务器与客户端之间时间偏差较大时，会导致缓存混乱

Cache-Control 的取值：

  - no-store: 直接禁止浏览器缓存数据(强缓存和协商缓存都不缓存)，每次用户请求该资源，都会向服务器发送一个请求，每次都会下载完整的资源
  - no-cache: 不使用本地缓存，需要使用协商缓存
  - immutable: 在缓存有效期内，即时用户刷新浏览器也不会向浏览器发起 http 请求
  - public: 可以被所有的用户缓存，包括终端用户和 CDN 等中间代理服务器
  - private: 只能被终端用户的浏览器缓存，不允许 CDN 等中间代理服务器缓存

`协商缓存 Last-Modified(HTTP/1.0) / Etag(HTTP/1.1)`
  协商缓存就是强制缓存失效后，浏览器携带缓存标识向服务器发送请求，由服务器根据缓存标识来决定是否使用缓存的过程

  1. 客户端携带获取的缓存标识发送 HTTP 请求 `If-Modified-Since / If-None-Match`
    If-Modified-Since = Last-Modified 的值，If-None-Match = Etag 的值
  2. 浏览器根据资源文件是否更新返回：
    + 2.1 没更新，返回 304，通知客户端读取缓存的信息
    + 2.2 更新了，返回 200 及最新的资源信息，以及 Last-Modified / Etag

为什么会有 Etag ?

  Etag 是 HTTP/1.1 新增的，主要是为了解决几个 Last-MOdified 难以解决的问题：
  1. 一些文件也许会周期性的更改，但是他的内容并不改变(仅仅只是修改时间)，这个时候我们并不希望客户端认为这个文件被修改了，而重新 get
  2. 某些文件修改非常频繁，比如在秒以下的时间内修改了，if-modified-since 能检查到的粒度是秒级的，这种修改无法判断
  3. 某些服务器不能精确的得到文件的最后修改时间

强缓存和协商缓存的区别：
  协商缓存总会和服务器协商，所以协商缓存总会向浏览器发送请求

强缓存和协商缓存都是针对静态资源文件

3. DNS解析

- 递归查询
- 迭代查询

查找DNS缓存：客户端 -> 浏览器缓存 -> 本地的hosts文件 -> 本地DNS解析协议 -> 本地DNS服务器
    
每一次 DNS 解析的时间在 20 ~ 120 毫秒

DNS解析优化：
  1. 一个产品尽量少去请求不同的服务器(域名)，减少 DNS 解析次数，但是一个被舍弃的方案
  2. DNS 预解析(dns-prefetch)

当代产品的开发，资源一般都是部署到不同的服务器上(特别是大型项目)
  - web资源服务器
  - 图片资源服务器
  - 数据接口服务器
  - 第三方服务器
  - ...

`服务器拆分的优势:`
- 资源的合理利用
- 抗压能力加强
- 提高HTTP并发能力

4. TCP三次握手(建立连接通道)

三次握手过程如下：
  1. 客户端通过向服务器发送一个 SYN 来创建一个主动打开，作为三次握手的一部分，客户端把这段连接的序列号设为随机数A
  2. 服务器端应当为一个合法的 SYN 返回一个 SYN/ACK，ACK的确认码为 A+1，并且 SYN/ACK 包本身又有另一个随机序号 B
  3. 最后，客户端再发送一个 ACK，当服务器收到这个 ACK 的时候，就完成了三次握手，并进入连接创建状态。此时包序号被设定为收到的确认号 A+1，而响应则为 B+1

问题：为什么是三次握手，而不是两次或者四次呢？

简单来说，就是要保证在一段有效时间内，双方收到对方的有效信息。A 发送给 B，B 回复 A，A 如果不再回复 B，B 怎么知道 A 可以收到呢

TCP 作为一种可靠传输控制协议，其核心思想：既要保证数据可靠传输，又要提高传输的效率。

5. 数据传输

- HTTP报文
  + 请求报文
  + 响应报文
- 响应状态码
  + 200 OK
  + 202 Accepted: 服务器已经接受请求，但尚未处理(异步)
  + 204 No Content: 服务器成功处理了请求，但不需要返回任何实体
  + 206 Paitial Content: 服务器已经成功处理了部分GET请求(主要用于断点续传)
  + 301 Moved Permanently: 永久重定向
  + 302 Moved Temporarily: 临时重定向
  + 304 Not Modified
  + 305 Use Proxy
  + 400 Bad Request: 请求参数有误
  + 401 Unauthorized: 未授权
  + 404 Not Found
  + 405 Method Not Allowed: 请求方法类型不对
  + 408 Request Timeout
  + 500 Internal Server Error
  + 503 Service Unavailable
  + 505 HTTP Version Not Supported
  + ...

- options 预检请求

  非简单请求会在正式通信之前，增加一次 HTTP 请求，被称为预检请求。浏览器会先发起 options 请求到服务器，以获知服务器是否允许该实际请求

- 简单请求和复杂请求

  1. 必须是 get / post / head 请求
  2. 请求头只能包含这些字段：Accept、Accept-Language、Content-Language、Content-Type、DPR、Downlink、Save-Data、Viewport-Width、Width
  3. Content-Type只能是这些值：text/plain、multipart/form-data、application/x-www-form-urlencoded
  4. 请求中的任意XMLHttpRequestUpload 对象均没有注册任何事件监听器；XMLHttpRequestUpload 对象可以使用 XMLHttpRequest.upload 属性访问。
  5. 请求中没有使用 ReadableStream 对象。

6. TCP四次挥手(关闭连接通道)

四次挥手过程如下：
  1. 客户端 A 发送一个 FIN，用来关闭客户端 A 到服务器 B 的数据传送
  2. 服务器 B 收到这个 FIN 后，它发回一个 ACK，确认序号为收到的序号加1
  3. 客户端 A 发送 FIN，服务器 B 是可以继续把它需要响应给客户端 A 的数据发送完，然后服务器 B 关闭与客户端 A的连接，发送一个 FIN 给客户端 A
  4. 客户端 A 发回 ACK 报文确认，并将确认序号设置为收到的序号加1

问题：为什么连接的时候是三次握手，关闭的时候却是四次挥手呢？
  - 服务器端收到客户端的SYN连接请求报文后，可以直接发送SYN+ACK报文
  - 但关闭连接时，当服务器端收到FIN报文后，很可能并不会立即关闭连接，所以只能先回复一个ACK报文，告诉客户端：“你发送的FIN报文我收到了”，只有等到服务器端所有的报文都发送完后，我才能发送FIN报文，因此不能一起发送，故需要四次握手

connection: keep-alive 建立长连接

## HTTP1.0 与 HTTP1.1 与 HTTP2.0

时间节点：HTTP1.0(1996)、 HTTP1.1(1999)、 HTTP2.0(2015)

### HTTP1.0 与 HTTP1.1 的区别

- `缓存处理`：HTTP1.0 主要使用 Expires、Last-modified，HTTP1.1 主要使用 Cache-Control、Etag
- `带宽优化及网络连接的使用`：HTTP1.1 支持断点续传，即返回状态码 206(Partial Content)
- `错误通知的管理`：在 HTTP1.1 中新增了 24 个错误状态响应码，如409(Conflict)表示请求的资源与资源当前的状态冲突了；410(Gone)表示服务器上的某个资源被永久删除了
- `Host头处理`：在 HTTP1.0 中认为每台服务器都绑定一个唯一的 IP 地址，因此，在请求消息的URL并没有传递主机名(hostname)。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机，并且它们共享一个 IP 地址。HTTP1.1 的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误 400(Bad Request)
- `长连接`：HTTP1.1 中默认开启 `Connection: keep-alive`，一定程度上弥补了 HTTP1.0 每次都要创建连接的缺点

### HTTP2.0 和 HTTP1.x相比的新特性

- `新的二进制格式`：HTTP1.x 的解析是基于文本，基于文本协议的格式解析存在天然的缺陷，文本的变现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认 0 和 1 的组合，基于这种考虑，HTTP2.0 的协议解析决定采用二进制，实现方便且健壮
- `header压缩`：HTTP1.x 的 header 带有大量的信息，而且每次都要重复发送，HTTP2.0 使用 encoder 来减少需要传输的 header大小，通讯双方各自 cache 一份 header fields 表，避免了重复 header 的传输，又减少了需要传输的大小
- `服务器推送`：例如我的网页有一个 style.css 的请求，在客户端收到 style.css 数据的同事，服务端会将 style.js 的文件推送给 客户端，当客户端再次尝试获取 style.js 的时候就可以直接从缓存中获取，不用再发请求了
- `多路复用`：
  + HTTP/1.0 每次请求响应，建立一个 TCP 连接，用完关闭
  + HTTP/1.1 长连接，若干个请求排队串行化单线程处理，后面的请求等待前面的请求的返回才能获得执行的机会，一旦有某个请求超时，后续的请求只能被阻塞，毫无办法，也就是人们常说的线头阻塞
  + HTTP/2.0 多路复用，多个请求可同时在一个连接上并行执行，某个请求任务耗时严重，不影响到其他连接的正常执行

  ### 性能优化汇总

  1. 利用缓存
    - 静态资源文件实现强缓存和协商缓存(扩展：文件有更新，如何保证及时刷新)
    - 对于不经常更新的接口数据采用本地存储做数据缓存(扩展：cookie / localStorage / vuex|redux 的区别)
  2. DNS 优化
    - 分服务器部署，增加 HTTP 的并发性(导致DNS解析变慢)
    - dns-prefetch
  3. TCP 的三次握手和四次挥手
    - Connection: keep-alive 建立长连接
  4. 数据传输
    - 减少数据传输的大小
      + 内容或者数据的压缩(webpack等)
      + 服务器一定要开启GZIP压缩(一般可以压缩60%左右)
      + 大批量数据分批次处理(下拉刷新、分页等)
    - 减少HTTP请求次数
      + 资源文件合并处理
      + 字体图标
      + 雪碧图
      + 图片base64
  5. CDN 服务器地域分布
  6. 采用HTTP/2.0

## 02. 数据缓存和本地存储

- localStorage
- sessionStorage
- cookie
- IndexedDB

localStorage 满足同源策略下的页面(不同的.html文件)是共享的，只要不手动清除或者卸载浏览器，就会一直存在本地存储中，它的大小最大为 5MB 左右
sessionStorage 同源策略下的页面(不同的.html文件)是不共享的，但是同一个页面的不同 iframe 中是共享的，仅在当前会话中有效，关闭页面或浏览器后即被清除，它的大小最大为 5MB 左右
cookie 是绑定在特定域名之下的，不同源之间的 cookie 是不能共享的，只要设置了 cookie，改源下发送的每一个 HTTP 请求都会自动带上 cookie，cookie 的大小只有 4KB，cookie 是有过期时间的，在过期时间内一直有效，即使关闭了页面或浏览器
IndexDB 是非关系型数据库，以键值对的形式存储数据，值也可以是 JS 对象，大小在 250MB 以上

cookie 与 session

cookie 是存储在客户端的，session 是存储在服务端，cookie 中存储有 sessionid，服务端根据 sessionid 返回 session 对象

http 是无状态的，cookie 中携带的 sessionID 可以标识用户